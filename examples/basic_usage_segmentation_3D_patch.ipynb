{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import med_dataloader as med_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "try:\n",
    "    shutil.rmtree(\"Test_Dataset_segmentation_patch_TF\")\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caching decoded images in Test_Dataset_segmentation_patch_TF\\CT.cache...\n",
      "[256 256 256 1]\n",
      "[256 256 256 1]\n",
      "[256 256 256 1]\n",
      "3/3\n",
      "Cached decoded images in Test_Dataset_segmentation_patch_TF\\CT.cache.\n",
      "Caching decoded images in Test_Dataset_segmentation_patch_TF\\Labels.cache...\n",
      "[256 256 256 1]\n",
      "[256 256 256 1]\n",
      "[256 256 256 1]\n",
      "3/3\n",
      "Cached decoded images in Test_Dataset_segmentation_patch_TF\\Labels.cache.\n"
     ]
    }
   ],
   "source": [
    "num_classes = 3\n",
    "\n",
    "med_dl.generate_dataset(data_path=r\"Test_Dataset_segmentation_patch.json\",\n",
    "                        imgA_label=\"CT\",\n",
    "                        imgB_label=\"Labels\",\n",
    "                        img_size=256,\n",
    "                        is_B_categorical=True,\n",
    "                        num_classes=num_classes,\n",
    "                        norm_boundsA=None,\n",
    "                        norm_boundsB=None,\n",
    "                        use_3D=True,\n",
    "                        patch_size=100,\n",
    "                        patch_overlap=0.0\n",
    "                        )\n",
    "\n",
    "train_ds, valid_ds, test_ds = med_dl.get_dataset(data_dir=r\"Test_Dataset_segmentation_patch_TF\",\n",
    "                                                 percentages=[1,0,0],\n",
    "                                                 batch_size=1,\n",
    "                                                 train_augmentation=True,\n",
    "                                                 random_crop_size=None,\n",
    "                                                 random_rotate=False,\n",
    "                                                 random_flip=False,\n",
    "                                                 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "slice_index = 80\n",
    "\n",
    "for batch in train_ds.take(3):\n",
    "#for batch in train_ds.skip(192*0+70).take(30):\n",
    "    volume_batch, label_batch = batch\n",
    "    for volume, label in zip(volume_batch, label_batch):\n",
    "        print(tf.shape(volume))\n",
    "        plt.subplot(121)\n",
    "        plt.imshow(volume[:,:,slice_index,0], cmap=\"gray\")\n",
    "        #plt.imshow(volume[:,:,0], cmap=\"gray\")\n",
    "        plt.subplot(122)\n",
    "        for i in range(num_classes):\n",
    "            plt.imshow(label[:,:,slice_index,i], cmap=\"gray\", alpha=0.5)\n",
    "            #plt.imshow(label[:,:,i], cmap=\"gray\", alpha=0.5)\n",
    "        plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import SimpleITK as sitk\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "path = r\"C:\\Users\\rossi\\Programming\\python_packages\\med_dataloader\\examples\\Test_Dataset_segmentation_patch\\CT\"\n",
    "path = os.path.join(path, \"volumeCT_reshape_knee_192_192_192_0001.mha\")\n",
    "img = sitk.GetArrayFromImage(sitk.ReadImage(path))\n",
    "img = np.transpose(img, axes=(2, 1, 0))\n",
    "img = tf.convert_to_tensor(img)\n",
    "\n",
    "img_size = 200\n",
    "\n",
    "if img_size % 2 != 0:\n",
    "    img_size += 1\n",
    "\n",
    "current_size = img.shape\n",
    "diff = [(img_size - x) // 2 for x in current_size]\n",
    "pad_amount = [x if x > 0 else 0 for x in diff]\n",
    "paddings = [[x, x] for x in pad_amount]\n",
    "img = tf.pad(img, paddings=paddings)\n",
    "\n",
    "current_size = img.shape\n",
    "diff = [(img_size - x) // 2 for x in current_size]\n",
    "crop_begins = [-x if x < 0 else 0 for x in diff]\n",
    "crop_ends = [img_size for _ in crop_begins]\n",
    "img = tf.slice(img, crop_begins, crop_ends)\n",
    "img = tf.expand_dims(img, axis=-1)\n",
    "img = tf.expand_dims(img, axis=0)\n",
    "print(tf.shape(img))\n",
    "\n",
    "plt.imshow(img[0,:,:,15,0], cmap=\"gray\")\n",
    "plt.show()\n",
    "\n",
    "patch_size = 92 # patch_shape\n",
    "overlap_perc = 0.5\n",
    "overlap=int(patch_size*overlap_perc)\n",
    "print(overlap)\n",
    "\n",
    "ksizes = [1, patch_size, patch_size, patch_size, 1]\n",
    "strides = [1, patch_size-overlap, patch_size-overlap, patch_size-overlap, 1]\n",
    "img = tf.extract_volume_patches(img, ksizes, strides,  'VALID')\n",
    "print(tf.shape(img))\n",
    "img = tf.reshape(img, [-1, patch_size, patch_size, patch_size])\n",
    "print(tf.shape(img))\n",
    "\n",
    "for p in range(10):\n",
    "    print(f\"Patch: {p}\")\n",
    "    for i in range(1):\n",
    "        plt.imshow(img[p, :, :, i], cmap=\"gray\")\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import SimpleITK as sitk\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "path = r\"C:\\Users\\rossi\\Programming\\python_packages\\med_dataloader\\examples\\Test_Dataset_segmentation_patch\\CT\"\n",
    "path = os.path.join(path, \"volumeCT_reshape_knee_192_192_192_0001.mha\")\n",
    "img = sitk.GetArrayFromImage(sitk.ReadImage(path))\n",
    "img = np.transpose(img, axes=(2, 1, 0))\n",
    "img = tf.convert_to_tensor(img)\n",
    "\n",
    "path = r\"C:\\Users\\rossi\\Programming\\python_packages\\med_dataloader\\examples\\Test_Dataset_segmentation_patch\\Labels\"\n",
    "path = os.path.join(path, \"volumeLabel_femur_tibia_192_192_192_0001.mha\")\n",
    "lab = sitk.GetArrayFromImage(sitk.ReadImage(path))\n",
    "lab = np.transpose(lab, axes=(2, 1, 0))\n",
    "lab = tf.convert_to_tensor(lab)\n",
    "\n",
    "img_size = 200\n",
    "\n",
    "if img_size % 2 != 0:\n",
    "    img_size += 1\n",
    "\n",
    "current_size = img.shape\n",
    "diff = [(img_size - x) // 2 for x in current_size]\n",
    "pad_amount = [x if x > 0 else 0 for x in diff]\n",
    "paddings = [[x, x] for x in pad_amount]\n",
    "img = tf.pad(img, paddings=paddings)\n",
    "lab = tf.pad(lab, paddings=paddings)\n",
    "\n",
    "current_size = img.shape\n",
    "diff = [(img_size - x) // 2 for x in current_size]\n",
    "crop_begins = [-x if x < 0 else 0 for x in diff]\n",
    "crop_ends = [img_size for _ in crop_begins]\n",
    "img = tf.slice(img, crop_begins, crop_ends)\n",
    "img = tf.expand_dims(img, axis=-1)\n",
    "img = tf.expand_dims(img, axis=0)\n",
    "print(tf.shape(img))\n",
    "\n",
    "lab = tf.slice(lab, crop_begins, crop_ends)\n",
    "lab = tf.expand_dims(lab, axis=-1)\n",
    "lab = tf.expand_dims(lab, axis=0)\n",
    "print(tf.shape(lab))\n",
    "\n",
    "_, axs = plt.subplots(1,2)\n",
    "axs[0].imshow(img[0,:,:,15,0], cmap=\"gray\")\n",
    "axs[1].imshow(lab[0,:,:,15,0], cmap=\"gray\")\n",
    "plt.show()\n",
    "\n",
    "patch_size = 100 # patch_shape\n",
    "overlap = 50\n",
    "\n",
    "ksizes = [1, patch_size, patch_size, patch_size, 1]\n",
    "strides = [1, patch_size-overlap, patch_size-overlap, patch_size-overlap, 1]\n",
    "img = tf.extract_volume_patches(img, ksizes, strides,  'VALID')\n",
    "print(tf.shape(img))\n",
    "img = tf.reshape(img, [-1, patch_size, patch_size, patch_size])\n",
    "print(tf.shape(img))\n",
    "\n",
    "lab = tf.extract_volume_patches(lab, ksizes, strides,  'VALID')\n",
    "print(tf.shape(lab))\n",
    "lab = tf.reshape(lab, [-1, patch_size, patch_size, patch_size])\n",
    "print(tf.shape(lab))\n",
    "\n",
    "for p in range(27):\n",
    "    print(f\"Patch: {p}\")\n",
    "    for i in range(1):\n",
    "        _, axs = plt.subplots(1,2)\n",
    "        axs[0].imshow(img[p, :, :, i], cmap=\"gray\")\n",
    "        axs[1].imshow(lab[p, :, :, i], cmap=\"gray\")\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "da8a66f4203e22c1b37f21a08c2a879bcd5a762c56ff24264da73fb1e7e29066"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "metadata": {
   "interpreter": {
    "hash": "31cce29e8fb201be9f4f5076271a9ab310f410b2e79720eb45fe746a4bcc676b"
   }
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
